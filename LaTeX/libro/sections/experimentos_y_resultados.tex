\section{Experimentos y Resultados}

En este capítulo se presentan los experimentos realizados, los modelos y las metodologías utilizadas en su entrenamiento, y los resultados de dichos experimentos.

\subsection{Síntesis de datos de entrenamiento}

Para las tareas de clasificación y segmentación es necesaria una verdad fundamental, ya sea una o varias etiquetas por cada imagen en el caso de la clasificación, o una máscara en el caso de la segmentación. Este es el objetivo que se quiere obtener a partir del modelo final.

Las imágenes de referencia se sintetizaron a partir de estudios de la zona del abanico aluvial del Pilcomayo \cite{baudino-2023}, en donde se presentan mapas de geomorfología como en la figura \ref{fig:6}, las cuales se imitaron a base del mejor esfuerzo. Para facilitar la identificación visual de los paleocauces, se utilizaron imágenes de color falso, en especial utilizando imágenes de luz infrarroja (IR) de onda corta (SWIR por sus siglas en ingles, short wave infrared) utilizando las bandas B12 (IR de onda corta), B8A (IR cercano) y B4 (verde) en los canales rojo, verde y azul respectivamente. Diferentes tipos de suelo y vegetación reflejan estas bandas de formas variadas, y esta combinación puede resaltar estructuras geológicas como paleocauces al ojo humano mejor que imágenes de color real. \cite{earth-observatory-false-color} Un ejemplo de mascara, usando el mapa de la figura \ref{fig:6} como referencia, se demuestra en la figura \ref{fig:7}. Para la creación de estas máscaras de entrenamiento se utilizaron herramientas de dibujo digital. Ejemplos de este tipo de programa incluyen {\it Krita} y {\it GIMP}.

\begin{figure}[h!]
    \centering
    \includegraphics[width=\textwidth]{img/abanico-pilcomayo.png}
    \caption{Mapa de geomorfología del abanico aluvial del Pilcomayo. \cite{baudino-2023}}
    \label{fig:6}
\end{figure}

\begin{figure}[h!]
    \centering
    \subfloat[Mapa SWIR de referencia, tesela T20KNA]{\includegraphics[width=0.4\textwidth]{img/T20KNA_swir.jpg}}
    \qquad
    \subfloat[Máscara de paleocauces]{\includegraphics[width=0.4\textwidth]{img/T20KNA_mask.jpg}}
    \caption{La creación de datos de entrenamiento implica la creación manual de máscaras que definen el objetivo}
    \label{fig:7}
\end{figure}

\subsection{Herramientas utilizadas}

% python libs, cuda, docker, qgis
La herramienta fundamental utilizada en los experimentos es la librería PyTorch \cite{Ansel_PyTorch_2_Faster_2024}, que implementa una gran cantidad de componentes básicos de Machine Learning, como las capas que componen a los modelos, los conjuntos de datos de entrenamiento, funciones de activación, funciones de utilidad, entre otros.

La librería Lightning \cite{Falcon_PyTorch_Lightning_2019} expande sobre esta base, añadiendo una capa de abstracción adicional que provee bucles de entrenamiento y validación y módulos de datos que facilitan la interacción con conjuntos de datos, permitiendo al usuario enfocarse en la arquitectura del modelo y los datos de entrenamiento en lugar del proceso de entrenamiento a bajo nivel.

Finalmente, una capa de abstracción adicional sobre Lightning es proveída por TorchGeo \cite{Stewart_TorchGeo_Deep_Learning_2024}, una librería especializada para el análisis de datos de observación terrestre. TorchGeo provee facilidades para la creación de conjuntos de datos que, además de los datos multiespectrales de la imagen propia, tienen en cuenta la geolocalización de cada imagen. También proveen algunos modelos, opcionalmente preentrenados.

Para la combinación de imágenes georreferenciadas, o para la inclusión de datos de georreferenciación a imágenes que no los tienen, se utilizó la librería Rasterio \cite{gillies_2019}.

Los experimentos se realizaron exclusivamente en hardware de consumidor. Se utilizaron dos máquinas:

\begin{enumerate}
    \item Una computadora portátil con un procesador de 12 núcleos lógicos, 16GiB de memoria RAM, y una tarjeta gráfica Nvidia GeForce GTX 1050 Ti, que cuenta con 4GiB de memoria de video.
    \item Una computadora de escritorio con un procesador de 12 núcleos lógicos, 32GiB de memoria RAM, y una tarjeta gráfica AMD Radeon RX 7600, que cuenta con 8GiB de memoria de video.
\end{enumerate}

Cabe resaltar que los experimentos se vieron limitados por estas en su envergadura, sin embargo son reproducibles en hardware más actual o profesional. En donde sea relevante, la máquina en la cual se hizo el entrenamiento se referencia por la enumeración anterior.

\subsubsection{Versiones de software}

En el cuadro \ref{table:versions} se detallan las versiones del software relevante utilizado.

\begin{table}[h!]
    \centering
    \begin{tabular}{ |l|r|l| }
        \hline

        \rowcolor{LightBlue}
        Nombre & Versión & Tipo \\
        \hline

        Python & 1.13.11 & Lenguaje de programación \\
        \hline

        Lightning \cite{Falcon_PyTorch_Lightning_2019} & 2.6.0 & Librería Python \\
        \hline

        Pytoch \cite{Falcon_PyTorch_Lightning_2019} &
        \begin{tabular}[c]{@{}l@{}}
            2.6.0 (variante CUDA)\\
            2.9.1+rocm6.4 (variante ROCm)\\
        \end{tabular} &
        Librería Python \\
        \hline

        TorchGeo \cite{Stewart_TorchGeo_Deep_Learning_2024} & 0.8.0 & Librería Python \\
        \hline

        Rasterio \cite{gillies_2019} & 1.4.4 & Librería Python \\
        \hline

        CUDA \cite{cuda} & 12.9.1 & Plataforma de cómputo GPU Nvidia \\
        \hline

        ROCm \cite{rocm} & 7.1.1 & Plataforma de cómputo GPU AMD \\
        \hline

    \end{tabular}
    \caption{Versiones del software utilizado}
    \label{table:versions}
\end{table}

\subsection{Partición de datos de entrenamiento}

\todo{diagram of $random_grid_cell_assignment$}

El conjunto de datos en PyTorch también se conoce como {\it Dataset}, y el componente que disponibiliza estos datos como {\it DataLoader}. Lightning provee una abstracción, el {\it DataModule}, que abstrae al Dataset y permite proveer DataLoaders distintos para las tareas de entrenamiento, validación, prueba e inferencia.

Para la división de datos en datasets de entrenamiento, validación y prueba, se utilizaron métodos proveídos por TorchGeo. El procedimiento consiste en dividir los datos de entrenamiento en celdas, las cuales se asignan pseudoaleatoriamente a subconjuntos de entrenamiento, validación y prueba en una proporción de 70/20/10 respectivamente. Para cada subconjunto, luego, definimos un DataLoader que provee acceso a los datos.

Las celdas en las cuales se dividen las imágenes no se solapan, y la estrategia de cada DataLoader puede ser elegida de acuerdo al objetivo de la etapa a la cual corresponde. Para el entrenamiento usamos un muestreo aleatorio, mientras que los DataLoaders de validación y de prueba hacen un muestreo por división en celdas, asegurando que toda el área de estos conjuntos se muestrean una sola vez y que el conjunto de imágenes creado es consistente para cada tanda de entrenamiento y para cada modelo entrenado sobre el conjunto.

Cada DataLoader produce imágenes de 128$\times$128 o 192$\times$192 píxeles recortadas de las celdas asignadas al DataLoader, correspondiente a áreas de 7680m$\times$7680m y 11520m$\times$11520m respectivamente. Las imágenes de cada tesela tienen dimensiones de 1830$\times$1830 píxeles de 60m$\times$60m, abarcando un área de $109'800$m por lado, o alrededor de 110km. La grilla en la que se dividen es de seis celdas de largo, abarcando cada celda un área cuadrada de 305 píxeles de largo, lo que permite producir 4 imágenes de validación o prueba por celda.

\subsection{Entrenamiento y validación}
\todo{clasificacion} % explain setup and failure, or only in discusion?

Para la tarea de segmentación, se utilizaron tres arquitecturas bien establecidas. Las arquitecturas proveídas por TorchGeo utilizadas fueron Foreground-Aware Relation Network, o FarSeg \cite{zheng2020foregroundawarerelationnetworkgeospatial}, y una red enteramente convolucional de cinco capas conocida simplemente como FCN por sus siglas en inglés, Fully-convolutional Network. Adicionalmente se utilizó una implementación de U-Net, una red enteramente convolucional muy conocida por sus aplicaciones en el campo de la medicina, pero tambien muy capaz en imágenes de teledetección. \cite{ronneberger2015unetconvolutionalnetworksbiomedical, khryashchev2018}

Lightning provee un componente llamado Trainer, que implementa bucles de entrenamiento, validación y prueba, y toma de entrada un modelo, un conjunto de datos, y parámetros de entrenamiento. Algunos parámetros son la cantidad mínima y máxima de épocas de entrenamiento, donde una época es una iteración del entrenamiento sobre el dataset, y una condición de detención temprana del entrenamiento si no mejora a lo largo de una cierta cantidad de tiempo.

El Trainer también brinda la posibilidad de definir un {\it checkpoint}, es decir un punto de control, que se encarga de mantener una copia de los parámetros del modelo en el punto en el que muestra el mejor rendimiento a lo largo del entrenamiento. Este checkpoint es la forma en la que el Trainer provee el modelo entrenado para luego ser usado en tareas de inferencia.

Más allá de estos procedimientos simples, la mayoría del esfuerzo fue dedicada a la creación del conjunto de datos etiquetados y a la verificación de los resultados brindados por el entrenamiento sobre estos.

\subsection{Resultados}

Para todos los experimentos, las únicas variables son los modelos usados y sus parámetros configurables, también llamados hiperparámetros. Los parámetros del Trainer y del DataModule, así como la semilla del generador de números pseudoaleatorios (PRNG) son iguales para todos los experimentos, y se detallan en el cuadro \ref{table:trainer}.

\begin{table}[ht!]
    \centering
    \begin{tabular}{ |l|r|r|p{8cm}| }
        \hline

        \rowcolor{LightBlue}
        Parámetro & Máquina 1 & Máq. 2 & Descripción \\
        \hline

        Nro. mínimo de épocas & 1 & 1 & Cantidad mínima de iteraciones por el conjunto de datos de entrenamiento. \\
        \hline

        Nro. máximo de épocas & 50 & 50 & Cantidad máxima de iteraciones por el conjunto de datos de entrenamiento.\\
        \hline

        Paciencia & 7 & 7 & Cantidad de épocas en las que el modelo no mejora la pérdida de validación antes de detener el entrenamiento. \\
        \hline

        Semilla PRNG & 42 & 42 & Valor inicial del estado del generador de números semialeatorios, empleado en, entre otras funciones, la creación de los valores iniciales de los diversos parámetros entrenables del modelo. \\
        \hline

        Tamaño de época & 1200 & 1200 & Tamaño efectivo del conjunto de datos de entrenamiento. Cantidad de imágenes, recortadas al azar de las celdas del dataset de entrenamiento, usadas para el entrenamiento en cada época. \\
        \hline

        Tamaño de imagen & 128 & 192 & Dimensión de cada recorte de los datasets en píxeles. Los recortes son cuadrados. \\
        \hline

        Tamaño de lote (batch) & 3 & 3 & Cantidad de imágenes cargadas y procesadas en cada paso de entrenamiento. Subdivide a cada época. \\
        \hline
    \end{tabular}
    \caption{Parámetros de entrenamiento generales}
    \label{table:trainer}
\end{table}

Para cada arquitectura, se realizaron experimentos con diferentes hiperparámetros, los cuales se detallan a continuación, además de resultados concretos en la forma de valores de la función de pérdida para el conjunto de prueba.

También se demuestran resultados en teselas nuevas, no utilizadas en el DataModule de entrenamiento, para demostrar las predicciones en datos completamente desconocidos. Estas teselas son aquellas cuya función es \enquote{Prueba} en el cuadro \ref{table:tiles} del capítulo anterior. En particular, la tesela T20KNC que incluye la frontera entre Paraguay y Bolivia, una sección del oeste del Parque Nacional Médanos del Chaco, y un sistema de paleocauces prominente hacia el sur del rio Parapetí en Bolivia, será utilizada como imagen de prueba.

Para la visualización de las predicciones, se convierten las matrices de salida al formato de imagen georreferenciada GeoTiff. Las predicciones de los modelos son matrices de números decimales, para los cuales un valor cercano a o mayor que $1.0$ significa una predicción de ocurrencia de paleocauce en ese píxel, mientras que un valor cercano a o menor que $0.0$ significa una predicción de ausencia de paleocauce en ese píxel. Estos valores se fijan al intérvalo $[0,1]$, con valores menores que 0 y mayores que 1 siendo convertidos a 0 y 1 respectivamente. La matriz resultante es la máscara de predicciones para una celda de $128\times128$ o $192\times192$ píxeles, y cada píxel se convierte a un valor en la escala de grises, con 0 y 1 correspondiendo a negro y blanco respectivamente.

Estas celdas de $128\times128$ o $192\times192$ píxeles se combinan para formar un mosaico de predicciones. Para mitigar los artefactos que pueden surgir en los bordes de estas celdas, estas se solapan ligeramente. Se toman pasos de la mitad del tamaño de lado de las celdas, que luego se combinan en una imagen, eligiendo el valor máximo para cada píxel. De esta manera podemos asegurar que la predicción en los bordes de cada imagen no se vea comprometida.

El tamaño de lote fue elegido por una limitación de memoria en la máquina 1, pero también se observó que un tamaño de lote mayor afecta negativamente al modelo resultante, inclusive en la máquina 2 con suficiente memoria.

\subsubsection{FCN}

La arquitectura más simple en este trabajo, consiste de cinco capas convolucionales con activación de tipo {\it LeakyReLU}, la cual mantiene valores positivos iguales y multiplica valores negativos por un número pequeño para minimizar su magnitud.

Los hiperparámetros seleccionados para los experimentos se detallan en el cuadro \ref{table:fcn}.

\begin{table}[ht!]
    \centering
    \begin{tabular}{ |>{\bf \columncolor{LightBlue}} c|c|c|c|c| }
        \hline

        \rowcolor{LightBlue}
        Versión & \bf Canales de entrada & \bf Nro. de filtros & \bf Mejor época & \bf Pérdida en prueba \\
        \hline

        1 & Todos (11) & 64 & 1 & 0.4675 \\
        \hline

        2 & Todos (11) & 96 & 2 & 0.4678 \\
        \hline

        3 & Todos (11) & 128 & 8 & 0.4721 \\
        \hline

        4 & Todos (11) & 256 & 4 & 0.4638 \\
        \hline

        5 & Todos (11) & 256 & 4 & 0.4630 \\
        \hline

    \end{tabular}
    \caption{Hiperparámetros y resultados de la arquitectura FCN. Entrenamiento en máquina 1.}
    \label{table:fcn}
\end{table}

Una arquitectura así de simple necesita de patrones simples y obvios para ser útil. Tal vez predeciblemente, esta arquitectura no dio resultados útiles, creando predicciones uniformes para cualquier tesela. Todos los experimentos resultan en un modelo que produce una máscara de probabilidades en la que cada píxel es negro, y la cantidad de épocas necesarias para alcanzar la menor pérdida sugiere que no se aprendieron patrones entre iteraciones.

\subsubsection{FarSeg}

La arquitectura Foreground-Aware Relation Network es una arquitectura diseñada para la segmentación geoespacial de objetos en imágenes de alta resolución espacial \cite{zheng2020foregroundawarerelationnetworkgeospatial}. Mientras que solamente utilizamos imágenes de 60m de resolución espacial, dieron resultados mucho más prometedores que FCN. Estos se muestran en el cuadro \ref{table:farseg}, además de los hiperparámetros utilizados.

La FarSeg utiliza una arquitectura de red neuronal en lo que se conoce como {\it Backbone}, o columna vertebral, en este caso ResNet \cite{he2015deepresiduallearningimage}. Esta columna cumple la función de extractor de características, las cuales son utilizadas por el resto del modelo para generar una predicción. Existe la opción de usar parámetros preentrenados para el Backbone, pero en estos experimentos se hizo el entrenamiento completo sin parámetros preentrenados.

Como la arquitectura FarSeg disponible a través de TorchGeo solo acepta tres canales de entrada, se utilizaron los conjuntos de bandas B4, B3, B2 que corresponden a los colores visibles rojo, verde, azul (RGB), y B12, B8A, B4 que corresponden a las bandas infrarrojo de onda corta o SWIR, infrarrojo de onda cercana o NIR, rojo (SWIR).

\begin{table}[ht!]
    \centering
    \begin{tabular}{ |>{\bf \columncolor{LightBlue}} c|c|c|c|c| }
        \hline

        \rowcolor{LightBlue}
        Versión & \bf Canales de entrada & \bf Backbone & \bf Mejor época & \bf Pérdida en prueba \\
        \hline

        1 & B4, B3, B2 & ResNet-18 & 1 & 0.6560 \\
        \hline

        2 & B12, B8A, B4 & ResNet-18 & 3 & 0.5866 \\
        \hline

        3 & B4, B3, B2 & ResNet-34 & 11 & 0.4682 \\
        \hline

        4 & B12, B8A, B4 & ResNet-34 & 7 & 0.5324 \\
        \hline

        5 & B4, B3, B2 & ResNet-50 & 19 & 0.4514 \\
        \hline

        6 & B12, B8A, B4 & ResNet-50 & 2 & 1.444 \\
        \hline

        7 & B4, B3, B2 & ResNet-50 & 27 & 0.4977 \\
        \hline

        8 & B12, B8A, B4 & ResNet-50 & 4 & 1.056 \\
        \hline

        9 & B4, B3, B2 & ResNet-101 & 12 & 0.5897 \\
        \hline

        10 & B12, B8A, B4 & ResNet-101 & 10 & 0.9042 \\
        \hline

        11 & B4, B3, B2 & ResNet-101 & 8 & 0.6233 \\
        \hline

        12 & B12, B8A, B4 & ResNet-101 & 5 & 0.5351 \\
        \hline

    \end{tabular}
    \caption{Hiperparámetros y resultados de la arquitectura FarSeg. Entrenamiento en máquina 1.}
    \label{table:farseg}
\end{table}

\begin{figure}
    \centering
    \subfloat[\centering Tesela T20KNC]{\includegraphics[width=0.4\textwidth]{img/T20KNC_large.png}}

    \subfloat[\centering FarSeg v. 3 (RGB)]{\includegraphics[width=0.4\textwidth]{img/farseg-34-rgb.png}}
    \quad
    \subfloat[\centering FarSeg v. 4 (SWIR)]{\includegraphics[width=0.4\textwidth]{img/farseg-34-swir.png}}

    \subfloat[\centering FarSeg v. 5 y 6 (RGB)]{\includegraphics[width=0.4\textwidth]{img/farseg-50-rgb.png}}
    \quad
    \subfloat[\centering FarSeg v. 9 y 11 (RGB)]{\includegraphics[width=0.4\textwidth]{img/farseg-101-rgb.png}}

    \caption{Máscaras de predicción de paleocauces de los modelos FarSeg}
    \label{fig:farseg}
\end{figure}

Mientras que el use de backbone más simples no dio buenos resultados, los modelos más grandes dieron resultados significantes. Interesantemente, los modelos con backbone ResNet-50 y entrenados sobre las bandas de color visible tomaron, en promedio, muchas más épocas para alcanzar su mejor rendimiento que los demás.

La figura \ref{fig:farseg} muestra las máscaras generadas por estos modelos.

Entre los resultados, los modelos con backbone ResNet-18 y ResNet-101 produjeron máscaras completamente negras, o con pocas áreas en las que predicen paleocauces. Sin embargo, aun más llamativo es el hecho que los modelos que utilizan las bandas B12, B8A, B4 producen máscaras enteramente negras, excepto con backbone ResNet-34.

Las máscaras producidas por los modelos que utilizan las bandas B4, B3, B2 presentan bordes de apariencia borrosa, lo que podría ser una consecuencia de la resolución espacial de las imágenes utilizadas.

Las máscaras producidas por los modelos entrenados con las bandas B12, B8A, B4 son similares a las producidas por FCN. Cada píxel de la máscara tiene el valor mínimo, y las pérdidas de las mejores versiones son mayores que la mayor versión de FCN.

\subsubsection{U-Net}

Una de las arquitecturas más conocidas para la tarea de segmentación es U-Net. La estructura consiste de varios niveles por los cuales desciende la imagen de entrada hasta llegar a un nivel de cuello de botella, de donde asciende nuevamente por los niveles hasta llegar a la resolución de la imagen de salida, que en este caso es igual a la resolución de la imagen de entrada.

En cada descenso a un nivel inferior, los datos crecen en la cantidad de canales y decrecen en la resolución de cada canal, es decir, la imagen disminuye en su tamaño. Inversamente, al ascender a un nivel superior, disminuye la cantidad de canales e incrementa la resolución de cada canal. El cuello de botella es el último nivel, en el cual la resolución es mínima y la cantidad de canales es máxima.

En adición a las conexiones entre niveles adyacentes, existen conexiones entre los caminos descendientes y ascendientes del mismo nivel, saltando niveles en estas conexiones.

Cada nivel tiene un tamaño que describe la cantidad de filtros, y debe ser el doble que el nivel anterior o la mitad del nivel siguiente. Cada nivel disminuye y aumenta la resolución de la imagen por un factor de 4, o sea un factor de 2 por cada dimensión.

Los hiperparámetros utilizados y los resultados de los experimentos se visualizan en los cuadros \ref{table:unet1} y \ref{table:unet2}.

\begin{table}[ht!]
    \centering
    \begin{tabular}{ |>{\bf \columncolor{LightBlue}} c|c|c|c|c| }
        \hline

        \rowcolor{LightBlue}
        Versión & \bf Canales de entrada & \bf Niveles & \bf Mejor época & \bf Pérdida en prueba \\
        \hline

        1 & Todos (11) & 64, 128, 256, 512 & 10 & 0.4421 \\
        \hline

        2 & Todos (11) & 64, 128, 256, 512 & 10 & 0.4576 \\
        \hline

        3 & Todos (11) & 32, 64, 128, 256, 512 & 14 & 0.4535 \\
        \hline

        4 & Todos (11) & 32, 64, 128, 256, 512 & 3 & 0.4520 \\
        \hline

        5 & Todos (11) & 64, 128, 256, 512, 1024 & 10 & 0.5412 \\
        \hline

        6 & Todos (11) & 64, 128, 256, 512, 1024 & 10 & 0.4426 \\
        \hline

    \end{tabular}
    \caption{Hiperparámetros y resultados de la arquitectura U-Net para imágenes de $128\times128$. Entrenamiento en máquina 1.}
    \label{table:unet1}
\end{table}

\begin{table}[ht!]
    \centering
    \begin{tabular}{ |>{\bf \columncolor{LightBlue}} c|c|c|c|c| }
        \hline

        \rowcolor{LightBlue}
        Versión & \bf Canales de entrada & \bf Niveles & \bf Mejor época & \bf Pérdida en prueba \\
        \hline

        7 & Todos (11) & 64, 128, 256, 512 & 11 & 0.4385 \\
        \hline

        8 & Todos (11) & 64, 128, 256, 512 & 6 & 0.4138 \\
        \hline

        9 & Todos (11) & 32, 64, 128, 256, 512 & 12 & 0.4205 \\
        \hline

        10 & Todos (11) & 32, 64, 128, 256, 512 & 12 & 0.4205 \\
        \hline

        11 & Todos (11) & 64, 128, 256, 512, 1024 & 12 & 0.4250 \\
        \hline

        12 & Todos (11) & 64, 128, 256, 512, 1024 & 16 & 0.4172 \\
        \hline

    \end{tabular}
    \caption{Hiperparámetros y resultados de la arquitectura U-Net para imágenes de $192\times192$. Entrenamiento en máquina 2.}
    \label{table:unet2}
\end{table}

\begin{figure}
    \centering
    \subfloat[\centering Tesela T20KNC]{\includegraphics[width=0.5\textwidth]{img/T20KNC_large.png}}

    \subfloat[\centering U-Net v. 1 y 2]{\includegraphics[width=0.3\textwidth]{img/unet-1_1-2.png}}
    \quad
    \subfloat[\centering U-Net v. 3 y 4]{\includegraphics[width=0.3\textwidth]{img/unet-1_3-4.png}}
    \quad
    \subfloat[\centering U-Net v. 5 y 6]{\includegraphics[width=0.3\textwidth]{img/unet-1_5-6.png}}

    \subfloat[\centering U-Net v. 7 y 8]{\includegraphics[width=0.3\textwidth]{img/unet-2_7-8.png}}
    \quad
    \subfloat[\centering U-Net v. 9 y 10]{\includegraphics[width=0.3\textwidth]{img/unet-2_9-10.png}}
    \quad
    \subfloat[\centering U-Net v. 11 y 12]{\includegraphics[width=0.3\textwidth]{img/unet-2_11-12.png}}

    \caption{Máscaras de predicción de paleocauces de los modelos U-Net}
    \label{fig:unet}
\end{figure}

La pérdida de estos modelos es en promedio menor que la pérdida promedio de los modelos anteriores, y las máscaras generadas son mucho más detalladas. Estas máscaras se muestran en la figura \ref{fig:unet}.

Observando los resultados producidos por los modelos entrenados, es evidente que el análisis de imágenes más pequeñas produce predicciones más limitadas, en donde solamente áreas con un contraste más pronunciado son designadas como áreas de paleocauces, mientras que el análisis de imágenes que cubren un área más extensa producen predicciones más similares a las máscaras de entrenamiento. Por ejemplo, las versiones 11 y 12 son las únicas que producen una predicción sustancial para los paleocauces a lo largo del margen izquierdo de la imagen.

Las versiones 9 y 10 producen predicciones muy limitadas para esta zona, que presenta características de paleocauces colmatados. Aquellas zonas, en las que estas versiones producen predicciones significantes, son húmedas, sugeriendo un posible sesgo hacia los paleocauces activos. Aun así, los resultados de estas versiones son claramente limitados, posiblemente debido a su arquitectura que presenta un nivel inicial de 32 capas en lugar de 64.

Una ventaja de las versiones 1-6 es que sus predicciones son más consistentes, con las versiones 7-12 dependiendo mucho más de la composición de los niveles.

\subsubsection{Predicción en conjunto}

Un problema con las máscaras generadas por los modelos es la cantidad de artefactos y diferencias en los resultados, aun con la misma arquitectura y la misma distribución de datos de entrenamiento. Por esta razón, también experimentamos con la creación de máscaras usando un conjunto de modelos, cuyos resultados fueron adicionados para generar una sola máscara. Esto permite generar mapas de calor más consistentes, en los cuales los puntos ciegos de un modelo pueden ser cubiertos por los puntos fuertes de otro.

Aun con las diferencias entre los modelos, es común encontrar zonas en las cuales ningún modelo predice ocurrencias de paleocauces, mientras que en otras zonas la mayoría predice positivamente con alta certeza.

\begin{figure}
    \centering
    \subfloat[\centering Combinación FarSeg]{\includegraphics[width=0.4\textwidth]{img/farseg-combined.png}}
    \quad
    \subfloat[\centering Tesela T20KNC con máscara combinada FarSeg]{\includegraphics[width=0.4\textwidth]{img/farseg-combined-screen.png}}

    \subfloat[\centering Combinación U-Net 1-6]{\includegraphics[width=0.4\textwidth]{img/unet-combined.png}}
    \quad
    \subfloat[\centering Tesela T20KNC con máscara combinada U-Net 1-6]{\includegraphics[width=0.4\textwidth]{img/unet-combined-screen.png}}

    \subfloat[\centering Combinación U-Net 7-12]{\includegraphics[width=0.4\textwidth]{img/unet-combined-large.png}}
    \quad
    \subfloat[\centering Tesela T20KNC con máscara combinada U-Net 7-12]{\includegraphics[width=0.4\textwidth]{img/unet-combined-large-screen.png}}

    \caption{Máscaras de predicción producidas por una combinación de las predicciones anteriores}
    \label{fig:combined}
\end{figure}

La figura \ref{fig:combined} muestra máscaras generadas por una combinación de las predicciones de varios modelos, presentando predicciones más completas.

\todo[inline]{add section about argentina and mariscal predictions in another subsection}

\subsection{Comparación con trabajos anteriores}

Existen varios trabajos investigando la ocurrencia de paleocauces en el Chaco Central Paraguayo y en el Chaco Argentino. De particular interés son aquellos trabajos que incluyen una prospección de estas áreas, ya sea un sondeo geoeléctrico o mediante la creación de pozos.

Dos investigaciones son de gran interés, la primera por parte del Instituto Nacional de Tecnología Industrial (INTI) de Argentina en la provincia de Chaco \cite{inti-2015}, y la segunda como parte de un proyecto de la organización World Wildlife Fund (WWF) Paraguay, realizada en el distrito de Mariscal Estigarribia, departamento Boquerón. \cite{garcia-2021}

\subsubsection{Provincia de Chaco, Argentina}

Los estudios geoeléctricos del INTI en la provincia de Chaco en Argentina, realizados en el año 2014, tuvieron como objetivos la transferencia de conocimientos especiales en lo referente a captación de águas subterráneas y la evaluación su disponibilidad mediante sondeos eléctricos verticales (SEV). El trabajo incluye la ubicación de estos sondeos, además de algunos pozos utilizados por miembros de la comunidad. \cite{inti-2015}

El área de estudio del trabajo se encuentra en el Departamento de Libertador San Martín, y en este los municipios de General San Martín, Laguna Limpia, La Eduvigis y Pampa del Indio. En estos municipios se realizaron sondeos y encuestas en los predios de varias familias de cada comunidad.

Cabe destacar que las ubicaciones en las cuales se reportan pozos y sondeos se encuentran todas al sur del río Bermejo. En esta zona, se pueden observar una serie de paleocauces que se extienden en paralelo al río, en su mayoría siendo paleocauces activos con mucha vegetación y una gran cantidad de lagunas en meandros de ríos, es decir, caminos sinusoidales creados por un río.

Creando máscaras de predicción y combinándolas con mapas del área, podemos comprobar si el modelo predice que estos pozos y sondeos se realizaron en zonas de ocurrencia de paleocauces. Los mapas de los alrededores de varias zonas estudiadas y las predicciones superpuestas sobre los mismos se encuentran en la figura \ref{fig:inti}, en donde zonas blancas son aquellas en las que los modelos predicen ocurrencia de paleocauces.

Las áreas incluidas se escojieron debido a la presencia de pozos en la cercanía de los sondeos, lo cual es un buen indicador de la posible ocurrencia de paleocauces en la zona. Estas son: Localidad Selvas del Río de Oro - Municipio La Eduviges correspondiente mapa (a) en la figura \ref{fig:inti}, Localidad Laguna Limpia correspondiente al mapa (d), Paraje Buena Vista - Predio Educacional EFA correspondiente al mapa (g), y Paraje 10 de Mayo correspondiente al mapa (j). Una de las zonas descritas en la investigación no fue sondeada, sin embargo contiene varios pozos utilizados por la comunidad en la Cuarta Legua 14, correspondiente al mapa (m) en la figura \ref{fig:inti}. Por esta razón, decidimos incluirla también.

Todas las localidades caen dentro de áreas en donde los modelos versiones 11 y 12, descritos en la tabla \ref{table:unet2}, predicen ocurrencias de paleocauces. Sin embargo, las versiones 9 y 10 predicen que solo dos de las cinco áreas sondeadas se encuentran sobre paleocauces, una se encuentra en la cercanía de una predicción significante, y las dos restantes se encuentran lejos de predicciones significantes.

Mientras que las versiones 9 y 10 parecen predecir positivamente sólo áreas muy húmedas, las versiones 11 y 12 son mucho más generales. Como

\begin{figure}
    \centering

    \subfloat[\centering SEVs izq. a der.: Hermelinda González (HG), Romina Aveiro (RA), Juana Amarilla (JA)]{\includegraphics[width=0.3\textwidth]{img/inti-ja_ra_hg.png}}
    \qquad
    \subfloat[\centering Superposición pred. v. 9 y 10]{\includegraphics[width=0.3\textwidth]{img/inti-ja_ra_hg-9-10.png}}
    \qquad
    \subfloat[\centering Superposición pred. v. 11 y 12]{\includegraphics[width=0.3\textwidth]{img/inti-ja_ra_hg-11-12.png}}

    \subfloat[\centering SEVs izq. a der.: Teófilo Cabrera (TC), Familia Zapata (Z)]{\includegraphics[width=0.3\textwidth]{img/inti-tc_z.png}}
    \qquad
    \subfloat[\centering Superposición pred. v. 9 y 10]{\includegraphics[width=0.3\textwidth]{img/inti-tc_z-9-10.png}}
    \qquad
    \subfloat[\centering Superposición pred. v. 11 y 12]{\includegraphics[width=0.3\textwidth]{img/inti-tc_z-11-12.png}}

    \subfloat[\centering SEV Predio Educacional EFA]{\includegraphics[width=0.3\textwidth]{img/inti-efa.png}}
    \qquad
    \subfloat[\centering Superposición pred. v. 9 y 10]{\includegraphics[width=0.3\textwidth]{img/inti-efa-9-10.png}}
    \qquad
    \subfloat[\centering Superposición pred. v. 11 y 12]{\includegraphics[width=0.3\textwidth]{img/inti-efa-11-12.png}}

    \subfloat[\centering SEV Paraje 10 de Mayo]{\includegraphics[width=0.3\textwidth]{img/inti-p10m.png}}
    \qquad
    \subfloat[\centering Superposición pred. v. 9 y 10]{\includegraphics[width=0.3\textwidth]{img/inti-p10m-9-10.png}}
    \qquad
    \subfloat[\centering Superposición pred. v. 11 y 12]{\includegraphics[width=0.3\textwidth]{img/inti-p10m-11-12.png}}

    \subfloat[\centering Pozo Cuarta Legua 14]{\includegraphics[width=0.3\textwidth]{img/inti-l14.png}}
    \qquad
    \subfloat[\centering Superposición pred. v. 9 y 10]{\includegraphics[width=0.3\textwidth]{img/inti-l14-9-10.png}}
    \qquad
    \subfloat[\centering Superposición pred. v. 11 y 12]{\includegraphics[width=0.3\textwidth]{img/inti-l14-11-12.png}}

    \caption{Predicciones en el área de estudio de las investigaciones del INTI en la provincia de Chaco, Argentina.}
    \label{fig:inti}
\end{figure}
